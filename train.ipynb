{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ydyh-KnUWTNV"
      ],
      "toc_visible": true,
      "history_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create Embeddings"
      ],
      "metadata": {
        "id": "lF_Oh67YSiTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/facebookresearch/esm.git\n",
        "!curl -O https://dl.fbaipublicfiles.com/fair-esm/examples/P62593_reprs.tar.gz\n",
        "!tar -xzf P62593_reprs.tar.gz\n",
        "!curl -O https://dl.fbaipublicfiles.com/fair-esm/examples/P62593.fasta\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqIb5K7mSuuT",
        "outputId": "bc4d44b1-1027-4131-835f-5ef431c4c78a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 24.5M  100 24.5M    0     0  11.6M      0  0:00:02  0:00:02 --:--:-- 11.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1719k  100 1719k    0     0  1396k      0  0:00:01  0:00:01 --:--:-- 1397k\n",
            "/content\n",
            "P62593.fasta  P62593_reprs  P62593_reprs.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-pyindex\n",
        "!pip install nvidia-tensorrt\n",
        "!pip install torch-tensorrt==<VERSION> -f https://github.com/pytorch/TensorRT/releases/expanded_assets/<VERSION>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uco4ZheMSw1m",
        "outputId": "e5154f37-d9ef-497b-8342-90750aafa304"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8418 sha256=b26bd8284ef43127562f27f2d0fb75cc22083176ce1e8aec3ced727d642faa0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/af/d0/7a12f82cab69f65d51107f48bcd6179e29b9a69a90546332b3\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17283 sha256=699529d4eb4863a5009eeabee34ea4da7cbfdb210803bce116cf1116d0f9fe45\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt, nvidia-tensorrt\n",
            "Successfully installed nvidia-tensorrt-99.0.0 tensorrt-8.6.1.post1\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install torch-tensorrt==<VERSION> -f https://github.com/pytorch/TensorRT/releases/expanded_assets/<VERSION>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t36_3B_UR50D\")"
      ],
      "metadata": {
        "id": "pyBgGE4cj7mY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc76b7b-5f40-4133-cc38-cdeb39527383"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/esm/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t36_3B_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t36_3B_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t36_3B_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t36_3B_UR50D-contact-regression.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiT-wtPJS-87",
        "outputId": "a386070b-60a4-41c3-c1ee-1d1f464bf33d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bfrl9-ndR3xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17daef5f-0e88-4037-82b7-bdf38d916cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JKMnItBwSPwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34777248-8798-4d95-d658-e78094babf5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/ESM2\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/MyDrive/ESM2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pEPbEoIPSUQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2660621-bccd-4bb7-a548-28cf93913216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'esm' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/esm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R7TqQE4lSXq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "0365a376-c96a-47d9-fb1a-ca6ecee1b690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/esm.git\n",
            "  Cloning https://github.com/facebookresearch/esm.git to /tmp/pip-req-build-to7r413p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/esm.git /tmp/pip-req-build-to7r413p\n",
            "  Resolved https://github.com/facebookresearch/esm.git to commit 2b369911bb5b4b0dda914521b9475cad1656b2ac\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fair-esm\n",
            "  Building wheel for fair-esm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fair-esm: filename=fair_esm-2.0.1-py3-none-any.whl size=105381 sha256=7a9d61566bd38a2ed2414fc68aa4b30bdb5614622999fd191215620f6ddee1cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-23h0mj23/wheels/f3/b2/ec/4db0b108f6367c7563f99b2445e1137d486003fb2f9bfd2f53\n",
            "Successfully built fair-esm\n",
            "Installing collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "esm"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/facebookresearch/esm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UJrgvSGnSZc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dda16e8-97fe-4593-9517-8b8c922357ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/ESM2/esm\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/MyDrive/ESM2/esm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jMlP9wv2Sf4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191fd1fc-3328-483a-e72e-9fb8ce622270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /gdrive/MyDrive/ESM2/esm/.git/\n"
          ]
        }
      ],
      "source": [
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python /gdrive/MyDrive/ESM2/esm/scripts/extract.py esm2_t36_3B_UR50D /gdrive/MyDrive/Alkaliphilic/alkaliAdd.fasta /gdrive/MyDrive/Alkaliphilic/ESM2_embeddings --include mean per_tok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_hni0WITRcJ",
        "outputId": "ede42d7a-fdf7-49ad-c99e-f21796d838f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read /gdrive/MyDrive/Alkaliphilic/alkaliAdd.fasta with 3262 sequences\n",
            "Processing 1 of 168 batches (67 sequences)\n",
            "Processing 2 of 168 batches (60 sequences)\n",
            "Processing 3 of 168 batches (52 sequences)\n",
            "Processing 4 of 168 batches (48 sequences)\n",
            "Processing 5 of 168 batches (45 sequences)\n",
            "Processing 6 of 168 batches (43 sequences)\n",
            "Processing 7 of 168 batches (41 sequences)\n",
            "Processing 8 of 168 batches (40 sequences)\n",
            "Processing 9 of 168 batches (39 sequences)\n",
            "Processing 10 of 168 batches (39 sequences)\n",
            "Processing 11 of 168 batches (39 sequences)\n",
            "Processing 12 of 168 batches (37 sequences)\n",
            "Processing 13 of 168 batches (37 sequences)\n",
            "Processing 14 of 168 batches (36 sequences)\n",
            "Processing 15 of 168 batches (36 sequences)\n",
            "Processing 16 of 168 batches (35 sequences)\n",
            "Processing 17 of 168 batches (35 sequences)\n",
            "Processing 18 of 168 batches (34 sequences)\n",
            "Processing 19 of 168 batches (33 sequences)\n",
            "Processing 20 of 168 batches (33 sequences)\n",
            "Processing 21 of 168 batches (32 sequences)\n",
            "Processing 22 of 168 batches (32 sequences)\n",
            "Processing 23 of 168 batches (32 sequences)\n",
            "Processing 24 of 168 batches (31 sequences)\n",
            "Processing 25 of 168 batches (31 sequences)\n",
            "Processing 26 of 168 batches (30 sequences)\n",
            "Processing 27 of 168 batches (30 sequences)\n",
            "Processing 28 of 168 batches (29 sequences)\n",
            "Processing 29 of 168 batches (29 sequences)\n",
            "Processing 30 of 168 batches (29 sequences)\n",
            "Processing 31 of 168 batches (28 sequences)\n",
            "Processing 32 of 168 batches (28 sequences)\n",
            "Processing 33 of 168 batches (28 sequences)\n",
            "Processing 34 of 168 batches (27 sequences)\n",
            "Processing 35 of 168 batches (27 sequences)\n",
            "Processing 36 of 168 batches (27 sequences)\n",
            "Processing 37 of 168 batches (27 sequences)\n",
            "Processing 38 of 168 batches (26 sequences)\n",
            "Processing 39 of 168 batches (26 sequences)\n",
            "Processing 40 of 168 batches (26 sequences)\n",
            "Processing 41 of 168 batches (26 sequences)\n",
            "Processing 42 of 168 batches (25 sequences)\n",
            "Processing 43 of 168 batches (25 sequences)\n",
            "Processing 44 of 168 batches (25 sequences)\n",
            "Processing 45 of 168 batches (24 sequences)\n",
            "Processing 46 of 168 batches (24 sequences)\n",
            "Processing 47 of 168 batches (24 sequences)\n",
            "Processing 48 of 168 batches (24 sequences)\n",
            "Processing 49 of 168 batches (23 sequences)\n",
            "Processing 50 of 168 batches (23 sequences)\n",
            "Processing 51 of 168 batches (23 sequences)\n",
            "Processing 52 of 168 batches (23 sequences)\n",
            "Processing 53 of 168 batches (23 sequences)\n",
            "Processing 54 of 168 batches (22 sequences)\n",
            "Processing 55 of 168 batches (22 sequences)\n",
            "Processing 56 of 168 batches (22 sequences)\n",
            "Processing 57 of 168 batches (22 sequences)\n",
            "Processing 58 of 168 batches (21 sequences)\n",
            "Processing 59 of 168 batches (21 sequences)\n",
            "Processing 60 of 168 batches (21 sequences)\n",
            "Processing 61 of 168 batches (21 sequences)\n",
            "Processing 62 of 168 batches (20 sequences)\n",
            "Processing 63 of 168 batches (20 sequences)\n",
            "Processing 64 of 168 batches (20 sequences)\n",
            "Processing 65 of 168 batches (20 sequences)\n",
            "Processing 66 of 168 batches (20 sequences)\n",
            "Processing 67 of 168 batches (20 sequences)\n",
            "Processing 68 of 168 batches (19 sequences)\n",
            "Processing 69 of 168 batches (19 sequences)\n",
            "Processing 70 of 168 batches (19 sequences)\n",
            "Processing 71 of 168 batches (19 sequences)\n",
            "Processing 72 of 168 batches (19 sequences)\n",
            "Processing 73 of 168 batches (19 sequences)\n",
            "Processing 74 of 168 batches (18 sequences)\n",
            "Processing 75 of 168 batches (18 sequences)\n",
            "Processing 76 of 168 batches (18 sequences)\n",
            "Processing 77 of 168 batches (18 sequences)\n",
            "Processing 78 of 168 batches (18 sequences)\n",
            "Processing 79 of 168 batches (18 sequences)\n",
            "Processing 80 of 168 batches (18 sequences)\n",
            "Processing 81 of 168 batches (17 sequences)\n",
            "Processing 82 of 168 batches (17 sequences)\n",
            "Processing 83 of 168 batches (17 sequences)\n",
            "Processing 84 of 168 batches (17 sequences)\n",
            "Processing 85 of 168 batches (17 sequences)\n",
            "Processing 86 of 168 batches (17 sequences)\n",
            "Processing 87 of 168 batches (16 sequences)\n",
            "Processing 88 of 168 batches (16 sequences)\n",
            "Processing 89 of 168 batches (16 sequences)\n",
            "Processing 90 of 168 batches (16 sequences)\n",
            "Processing 91 of 168 batches (16 sequences)\n",
            "Processing 92 of 168 batches (16 sequences)\n",
            "Processing 93 of 168 batches (16 sequences)\n",
            "Processing 94 of 168 batches (15 sequences)\n",
            "Processing 95 of 168 batches (15 sequences)\n",
            "Processing 96 of 168 batches (15 sequences)\n",
            "Processing 97 of 168 batches (15 sequences)\n",
            "Processing 98 of 168 batches (15 sequences)\n",
            "Processing 99 of 168 batches (15 sequences)\n",
            "Processing 100 of 168 batches (15 sequences)\n",
            "Processing 101 of 168 batches (15 sequences)\n",
            "Processing 102 of 168 batches (14 sequences)\n",
            "Processing 103 of 168 batches (14 sequences)\n",
            "Processing 104 of 168 batches (14 sequences)\n",
            "Processing 105 of 168 batches (14 sequences)\n",
            "Processing 106 of 168 batches (14 sequences)\n",
            "Processing 107 of 168 batches (14 sequences)\n",
            "Processing 108 of 168 batches (14 sequences)\n",
            "Processing 109 of 168 batches (14 sequences)\n",
            "Processing 110 of 168 batches (14 sequences)\n",
            "Processing 111 of 168 batches (13 sequences)\n",
            "Processing 112 of 168 batches (13 sequences)\n",
            "Processing 113 of 168 batches (13 sequences)\n",
            "Processing 114 of 168 batches (13 sequences)\n",
            "Processing 115 of 168 batches (13 sequences)\n",
            "Processing 116 of 168 batches (13 sequences)\n",
            "Processing 117 of 168 batches (13 sequences)\n",
            "Processing 118 of 168 batches (13 sequences)\n",
            "Processing 119 of 168 batches (13 sequences)\n",
            "Processing 120 of 168 batches (12 sequences)\n",
            "Processing 121 of 168 batches (12 sequences)\n",
            "Processing 122 of 168 batches (12 sequences)\n",
            "Processing 123 of 168 batches (12 sequences)\n",
            "Processing 124 of 168 batches (12 sequences)\n",
            "Processing 125 of 168 batches (12 sequences)\n",
            "Processing 126 of 168 batches (12 sequences)\n",
            "Processing 127 of 168 batches (12 sequences)\n",
            "Processing 128 of 168 batches (11 sequences)\n",
            "Processing 129 of 168 batches (11 sequences)\n",
            "Processing 130 of 168 batches (11 sequences)\n",
            "Processing 131 of 168 batches (11 sequences)\n",
            "Processing 132 of 168 batches (11 sequences)\n",
            "Processing 133 of 168 batches (11 sequences)\n",
            "Processing 134 of 168 batches (11 sequences)\n",
            "Processing 135 of 168 batches (11 sequences)\n",
            "Processing 136 of 168 batches (10 sequences)\n",
            "Processing 137 of 168 batches (10 sequences)\n",
            "Processing 138 of 168 batches (10 sequences)\n",
            "Processing 139 of 168 batches (10 sequences)\n",
            "Processing 140 of 168 batches (10 sequences)\n",
            "Processing 141 of 168 batches (10 sequences)\n",
            "Processing 142 of 168 batches (10 sequences)\n",
            "Processing 143 of 168 batches (10 sequences)\n",
            "Processing 144 of 168 batches (9 sequences)\n",
            "Processing 145 of 168 batches (9 sequences)\n",
            "Processing 146 of 168 batches (9 sequences)\n",
            "Processing 147 of 168 batches (9 sequences)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Classifier"
      ],
      "metadata": {
        "id": "OWvJhrnQSn_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisite"
      ],
      "metadata": {
        "id": "t7wab2bIT28d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.12"
      ],
      "metadata": {
        "id": "IzoLC55AT4ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqvolxWQx8uC",
        "outputId": "ebd57703-bbdc-4e18-ba6b-63bf7fcb7e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.9\n"
          ]
        }
      ],
      "source": [
        "pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71NgultbyHY3",
        "outputId": "a15f769e-351a-4968-afe1-5ae4b92308bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-evaluation\n",
            "  Downloading sklearn_evaluation-0.12.0-py3-none-any.whl (111 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/111.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ploomber-core>=0.2.6 (from sklearn-evaluation)\n",
            "  Downloading ploomber_core-0.2.22-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (3.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (4.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (3.1.3)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (1.5.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (5.9.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (7.34.0)\n",
            "Collecting black (from sklearn-evaluation)\n",
            "  Downloading black-23.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.8.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ploomber-core>=0.2.6->sklearn-evaluation) (6.0.1)\n",
            "Collecting posthog (from ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading posthog-3.3.2-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->sklearn-evaluation)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (23.2)\n",
            "Collecting pathspec>=0.9.0 (from black->sklearn-evaluation)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (4.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (4.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->sklearn-evaluation)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->sklearn-evaluation) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-evaluation) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (3.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (0.17.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->sklearn-evaluation) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->sklearn-evaluation) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->sklearn-evaluation) (1.16.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2.31.0)\n",
            "Collecting monotonic>=1.5 (from posthog->ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2023.11.17)\n",
            "Installing collected packages: monotonic, pathspec, mypy-extensions, jedi, backoff, posthog, black, ploomber-core, sklearn-evaluation\n",
            "Successfully installed backoff-2.2.1 black-23.12.1 jedi-0.19.1 monotonic-1.6 mypy-extensions-1.0.0 pathspec-0.12.1 ploomber-core-0.2.22 posthog-3.3.2 sklearn-evaluation-0.12.0\n"
          ]
        }
      ],
      "source": [
        "pip install sklearn-evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoTuyH3VsxAI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data utilities\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "import torch\n",
        "import h5py\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, make_scorer, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za3QBj3Z-UpS"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFMl0ZAH-UpT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W1LimhTfpEb",
        "outputId": "2fa08812-d014-4390-947d-7798d390101a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-23 00:52:28--  https://raw.githubusercontent.com/33220311/Alkaliphilic/main/Dataset/alkaliSplitNoFragment.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 679353 (663K) [text/plain]\n",
            "Saving to: ‘alkaliSplitNoFragment.csv’\n",
            "\n",
            "\r          alkaliSpl   0%[                    ]       0  --.-KB/s               \ralkaliSplitNoFragme 100%[===================>] 663.43K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-01-23 00:52:28 (128 MB/s) - ‘alkaliSplitNoFragment.csv’ saved [679353/679353]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/Alkaliphilic/main/Dataset/alkaliSplitNoFragment.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydyh-KnUWTNV"
      },
      "source": [
        "## Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsbWeA0qjBvb"
      },
      "outputs": [],
      "source": [
        "def error_rate(testing_labels, predicted_testing_labels):\n",
        "  from sklearn.metrics import f1_score, matthews_corrcoef, balanced_accuracy_score\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.metrics import recall_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  f1_performances = list()\n",
        "  sn = list()\n",
        "  sp = list()\n",
        "  Y = np.array(testing_labels) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(predicted_testing_labels) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  metric = matthews_corrcoef # the metric you want to compute\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append( matthews_corrcoef(testing_labels[subset], predicted_testing_labels[subset]) )\n",
        "    performances.append(accuracy_score(testing_labels[subset], predicted_testing_labels[subset]))\n",
        "    f1_performances.append(f1_score(testing_labels[subset], predicted_testing_labels[subset]))\n",
        "    sn.append(recall_score(testing_labels[subset], predicted_testing_labels[subset],labels=[1],average='macro'))\n",
        "    sp.append(recall_score(testing_labels[subset], predicted_testing_labels[subset],labels=[1],average='macro'))\n",
        "  sd_mcc = np.std(bootstrap_performances) # compute std deviation over the bootstrapped performances\n",
        "  sd_acc = np.std(performances)\n",
        "  sd_f1 = np.std(f1_performances)\n",
        "  sd_sn = np.std(sn)\n",
        "  sd_sp = np.std(sp)\n",
        "\n",
        "  print('acc:',accuracy_score(testing_labels, predicted_testing_labels))\n",
        "  print('f1:',f1_score(testing_labels, predicted_testing_labels))\n",
        "  print('mcc:',matthews_corrcoef(testing_labels, predicted_testing_labels))\n",
        "  print('sn:',sn)\n",
        "  print('sp:',sp)\n",
        "  print('sd_acc:',sd_acc)\n",
        "  print('sd_f1:',sd_f1)\n",
        "  print('sd_mcc:',sd_mcc)\n",
        "  print('sd_sn:',sd_sn)\n",
        "  print('sd_sp:',sd_sp)\n",
        "  print(classification_report(testing_labels, predicted_testing_labels))\n",
        "\n",
        "  return (sd_acc, sd_mcc, sd_f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def std_acc(clf,X,y):\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append( accuracy_score(y[subset], y_pred[subset]) )\n",
        "  sd_acc = np.std(bootstrap_performances)*1.96\n",
        "  return sd_acc"
      ],
      "metadata": {
        "id": "w6PR3SV7UXnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVliDqi8V-my"
      },
      "outputs": [],
      "source": [
        "def std_f1(clf,X,y):\n",
        "  from sklearn.metrics import f1_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append(f1_score(y[subset], y_pred[subset]) )\n",
        "  sd_f1 = np.std(bootstrap_performances)*1.96\n",
        "  return sd_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSi3pZGMV-3Y"
      },
      "outputs": [],
      "source": [
        "def std_mcc(clf,X,y):\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append(matthews_corrcoef(y[subset], y_pred[subset]) )\n",
        "  sd_mcc = np.std(bootstrap_performances)*1.96\n",
        "  return sd_mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "likEAElkX5Vz"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "def save_coefficients(classifier, filename):\n",
        "    \"\"\"Save the coefficients of a linear model into a .h5 file.\"\"\"\n",
        "    with h5py.File(filename, 'w') as hf:\n",
        "        hf.create_dataset(\"coef\",  data=classifier.coef_)\n",
        "        hf.create_dataset(\"intercept\",  data=classifier.intercept_)\n",
        "        hf.create_dataset(\"classes\", data=classifier.classes_)\n",
        "\n",
        "def load_coefficients(classifier, filename):\n",
        "    \"\"\"Attach the saved coefficients to a linear model.\"\"\"\n",
        "    with h5py.File(filename, 'r') as hf:\n",
        "        coef = hf['coef'][:]\n",
        "        intercept = hf['intercept'][:]\n",
        "        classes = hf['classes'][:]\n",
        "    classifier.coef_ = coef\n",
        "    classifier.intercept_ = intercept\n",
        "    classifier.classes_ = classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrEQOWRAufE"
      },
      "source": [
        "## Open embedding file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn6qNd85C6bx"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Alkaliphilic/ESM2_embeddings'\n",
        "delete = []\n",
        "embeddings = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8A4aZOotEMQ"
      },
      "outputs": [],
      "source": [
        "proteins = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfNnO9qltX6v"
      },
      "outputs": [],
      "source": [
        "annotations = read_csv('alkaliSplitNoFragment.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t36iDvOQti9m",
        "outputId": "1515a532-d7da-4488-c3d5-88c47200c978"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  identifier                                           sequence  label    set\n",
              "0   GAE35297  MMFGRFTERAQKVLALAQEEAVRLGHNNIGTEHILLGLIREGEGIA...      1  train\n",
              "1   GAE33564  MFRTVLVDDEVFVRQGLKSLIDWEECGFEVVAEAANGEDALKIIKD...      1  train\n",
              "2   PQQ65477  MKKVKLMVAITMMVCFLMTGVSFAEDGYLDSDYFNSVMDMIEDSYS...      1  train"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf6d89f3-0c7b-440c-b436-7c449f77685c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>sequence</th>\n",
              "      <th>label</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GAE35297</td>\n",
              "      <td>MMFGRFTERAQKVLALAQEEAVRLGHNNIGTEHILLGLIREGEGIA...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GAE33564</td>\n",
              "      <td>MFRTVLVDDEVFVRQGLKSLIDWEECGFEVVAEAANGEDALKIIKD...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PQQ65477</td>\n",
              "      <td>MKKVKLMVAITMMVCFLMTGVSFAEDGYLDSDYFNSVMDMIEDSYS...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf6d89f3-0c7b-440c-b436-7c449f77685c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf6d89f3-0c7b-440c-b436-7c449f77685c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf6d89f3-0c7b-440c-b436-7c449f77685c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23495a74-cabf-456a-a125-0ec2fc3f38f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23495a74-cabf-456a-a125-0ec2fc3f38f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23495a74-cabf-456a-a125-0ec2fc3f38f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "annotations[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eScyOlMFtGjH"
      },
      "outputs": [],
      "source": [
        "for filename in annotations.identifier:\n",
        "    file = os.path.join(path, filename + suffix)\n",
        "    if (os.path.exists(file)):\n",
        "      result = torch.load(file)\n",
        "      rep = result.get('mean_representations')\n",
        "      val = rep.values()\n",
        "      val = list(val)\n",
        "      val = np.array(val[0])\n",
        "      val = np.reshape(val,(-1,1280))\n",
        "      proteins.append((filename,val))\n",
        "    else:\n",
        "      delete.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdwva6fUtkxW"
      },
      "outputs": [],
      "source": [
        "train_set = annotations[annotations.set == \"train\"]\n",
        "test_set = annotations[annotations.set == \"test\"]\n",
        "print(f\"The train set contains {len(train_set)} samples, and we will test on {len(test_set)} samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN1PpTc3tw-o",
        "outputId": "d08ca147-9afe-4237-bbdd-6ed9dd89c216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2294\n",
            "2294\n"
          ]
        }
      ],
      "source": [
        "training_identifiers = train_set.identifier.values\n",
        "training_labels = train_set.label.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfK4RZisuE63",
        "outputId": "2d03885b-9a5f-453b-f912-83a6aa24d4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "574\n",
            "574\n"
          ]
        }
      ],
      "source": [
        "testing_identifiers = test_set.identifier.values\n",
        "testing_labels = test_set.label.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeo0RsDewH6e"
      },
      "outputs": [],
      "source": [
        "seq = dict(proteins)\n",
        "delete = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw7Gs-Ovu1gR"
      },
      "outputs": [],
      "source": [
        "training_embeddings = list()\n",
        "for identifier in training_identifiers:\n",
        "  embedding = seq[identifier]\n",
        "  training_embeddings.append(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu95EwOVxceu"
      },
      "outputs": [],
      "source": [
        "testing_embeddings = list()\n",
        "for identifier in testing_identifiers:\n",
        "  embedding = seq[identifier]\n",
        "  testing_embeddings.append(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq2HsFdtxkpE"
      },
      "outputs": [],
      "source": [
        "# A sanity check: make sure that the numbers are equal!\n",
        "assert(len(training_identifiers) == len(training_embeddings))\n",
        "assert(len(testing_identifiers) == len(testing_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_train = np.array(training_embeddings)\n",
        "nsample, nx, ny = arr_train.shape\n",
        "train_dataset = arr_train.reshape((nsample, nx*ny))\n",
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "E8otCp6kWPCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_test = np.array(testing_embeddings)\n",
        "nsample, nx, ny = arr_test.shape\n",
        "test_dataset = arr_test.reshape((nsample, nx*ny))\n",
        "test_dataset.shape"
      ],
      "metadata": {
        "id": "gG1_pZPnWRCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HSWJWepzWVb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpez8nyOvPOF"
      },
      "source": [
        "## Train MLP with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qFh0Bks9Obs"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvwGlWGl9Obt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vug_DpuSylO-"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 8\n",
        "\n",
        "multilayerperceptron = MLPClassifier(solver='lbfgs', random_state=10, max_iter=1000)\n",
        "\n",
        "parameters = {\n",
        "    'hidden_layer_sizes': [(2560,)],\n",
        "    #'learning_rate_init': [0.001],\n",
        "    'solver':['sgd', 'adam', 'lbfgs'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpuv4NyAutz1"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlth5o02yn-d",
        "outputId": "e9edbaee-283f-493f-abf0-659594e5ad7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Basic Protocol 3 — Step 9\n",
        "\n",
        "classifiers = GridSearchCV(multilayerperceptron, parameters, cv=10, scoring=metrics, refit='mcc')\n",
        "history = classifiers.fit(train_dataset, training_labels)\n",
        "classifier = classifiers.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMv8_JC0WcSQ",
        "outputId": "34200320-5249-402d-af45-1bdb8592c749"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'alpha': 0.0001,\n",
              " 'batch_size': 'auto',\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 1e-08,\n",
              " 'hidden_layer_sizes': (2560,),\n",
              " 'learning_rate': 'constant',\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_fun': 15000,\n",
              " 'max_iter': 1000,\n",
              " 'momentum': 0.9,\n",
              " 'n_iter_no_change': 10,\n",
              " 'nesterovs_momentum': True,\n",
              " 'power_t': 0.5,\n",
              " 'random_state': 10,\n",
              " 'shuffle': True,\n",
              " 'solver': 'sgd',\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': False,\n",
              " 'warm_start': False}"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkLigimLWROf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kMYQTWrF_05C",
        "outputId": "e1d0fa1f-7fa9-4596-e306-2d11fbe65de6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2805a5bd-48e0-4f56-a342-5714ea1e34ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>split2_test_accuracy</th>\n",
              "      <th>...</th>\n",
              "      <th>split3_test_mcc</th>\n",
              "      <th>split4_test_mcc</th>\n",
              "      <th>split5_test_mcc</th>\n",
              "      <th>split6_test_mcc</th>\n",
              "      <th>split7_test_mcc</th>\n",
              "      <th>split8_test_mcc</th>\n",
              "      <th>split9_test_mcc</th>\n",
              "      <th>mean_test_mcc</th>\n",
              "      <th>std_test_mcc</th>\n",
              "      <th>rank_test_mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>898.075153</td>\n",
              "      <td>126.626984</td>\n",
              "      <td>0.029225</td>\n",
              "      <td>0.005931</td>\n",
              "      <td>(2560,)</td>\n",
              "      <td>sgd</td>\n",
              "      <td>{'hidden_layer_sizes': (2560,), 'solver': 'sgd'}</td>\n",
              "      <td>0.895652</td>\n",
              "      <td>0.939130</td>\n",
              "      <td>0.904348</td>\n",
              "      <td>...</td>\n",
              "      <td>0.845924</td>\n",
              "      <td>0.835626</td>\n",
              "      <td>0.864598</td>\n",
              "      <td>0.741428</td>\n",
              "      <td>0.706486</td>\n",
              "      <td>0.669972</td>\n",
              "      <td>0.749897</td>\n",
              "      <td>0.783664</td>\n",
              "      <td>0.064643</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129.761909</td>\n",
              "      <td>20.076455</td>\n",
              "      <td>0.030423</td>\n",
              "      <td>0.007361</td>\n",
              "      <td>(2560,)</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'hidden_layer_sizes': (2560,), 'solver': 'adam'}</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.926087</td>\n",
              "      <td>0.904348</td>\n",
              "      <td>...</td>\n",
              "      <td>0.837716</td>\n",
              "      <td>0.786293</td>\n",
              "      <td>0.884226</td>\n",
              "      <td>0.779742</td>\n",
              "      <td>0.696454</td>\n",
              "      <td>0.640303</td>\n",
              "      <td>0.691928</td>\n",
              "      <td>0.761304</td>\n",
              "      <td>0.077410</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>403.229758</td>\n",
              "      <td>47.254076</td>\n",
              "      <td>0.071163</td>\n",
              "      <td>0.015532</td>\n",
              "      <td>(2560,)</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>{'hidden_layer_sizes': (2560,), 'solver': 'lbf...</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.917391</td>\n",
              "      <td>0.878261</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777442</td>\n",
              "      <td>0.748937</td>\n",
              "      <td>0.815781</td>\n",
              "      <td>0.734649</td>\n",
              "      <td>0.666967</td>\n",
              "      <td>0.587689</td>\n",
              "      <td>0.628575</td>\n",
              "      <td>0.715127</td>\n",
              "      <td>0.075362</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2805a5bd-48e0-4f56-a342-5714ea1e34ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2805a5bd-48e0-4f56-a342-5714ea1e34ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2805a5bd-48e0-4f56-a342-5714ea1e34ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f361660-def4-4a64-9b03-6f5c5052df9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f361660-def4-4a64-9b03-6f5c5052df9d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f361660-def4-4a64-9b03-6f5c5052df9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0     898.075153    126.626984         0.029225        0.005931   \n",
              "1     129.761909     20.076455         0.030423        0.007361   \n",
              "2     403.229758     47.254076         0.071163        0.015532   \n",
              "\n",
              "  param_hidden_layer_sizes param_solver  \\\n",
              "0                  (2560,)          sgd   \n",
              "1                  (2560,)         adam   \n",
              "2                  (2560,)        lbfgs   \n",
              "\n",
              "                                              params  split0_test_accuracy  \\\n",
              "0   {'hidden_layer_sizes': (2560,), 'solver': 'sgd'}              0.895652   \n",
              "1  {'hidden_layer_sizes': (2560,), 'solver': 'adam'}              0.852174   \n",
              "2  {'hidden_layer_sizes': (2560,), 'solver': 'lbf...              0.839130   \n",
              "\n",
              "   split1_test_accuracy  split2_test_accuracy  ...  split3_test_mcc  \\\n",
              "0              0.939130              0.904348  ...         0.845924   \n",
              "1              0.926087              0.904348  ...         0.837716   \n",
              "2              0.917391              0.878261  ...         0.777442   \n",
              "\n",
              "   split4_test_mcc  split5_test_mcc  split6_test_mcc  split7_test_mcc  \\\n",
              "0         0.835626         0.864598         0.741428         0.706486   \n",
              "1         0.786293         0.884226         0.779742         0.696454   \n",
              "2         0.748937         0.815781         0.734649         0.666967   \n",
              "\n",
              "   split8_test_mcc  split9_test_mcc  mean_test_mcc  std_test_mcc  \\\n",
              "0         0.669972         0.749897       0.783664      0.064643   \n",
              "1         0.640303         0.691928       0.761304      0.077410   \n",
              "2         0.587689         0.628575       0.715127      0.075362   \n",
              "\n",
              "   rank_test_mcc  \n",
              "0              1  \n",
              "1              2  \n",
              "2              3  \n",
              "\n",
              "[3 rows x 46 columns]"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DataFrame(classifiers.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vFSrlejaAc5"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(classifiers.cv_results_)\n",
        "df.to_excel('/content/drive/MyDrive/Alkaliphilic/MLPESM23B(1).xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6XZ9vilAJoD",
        "outputId": "837075bc-a801-440f-a568-1421c5712e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our model has an accuracy of 0.89\n"
          ]
        }
      ],
      "source": [
        "predicted_testing_labels = classifier.predict(test_dataset)\n",
        "accuracy = accuracy_score(testing_labels, predicted_testing_labels)\n",
        "error_rate(testing_labels, predicted_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViDDElvGBnf6"
      },
      "outputs": [],
      "source": [
        "# Further metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Data visualization\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqKqqPfoBvZ7"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_testing_labels, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)"
      ]
    }
  ]
}